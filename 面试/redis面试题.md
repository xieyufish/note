# Redis面试题

## 1. Redis中的数据类型？

1. 字符串（String）：`set key value`，string类型是二进制安全的，意思是redis的string可以包含任何数据。比如jpg图片或者序列化的对象。是redis里面最基本的数据类型，一个建最大能存储512MB；
2. 哈希（hash）：`hmset name key1 value1 key2 value2`，Redis hash是一个键值对集合，是一个string类型的key和value的映射表，hash特别适合用于存储对象；
3. 列表（list）：redis列表是简单的字符串列表，按照插入顺序排序。你可以添加一个元素到列表的头部或者尾部；`lpush name value`、`rpush name value`、 `lrem name index`、 `llen name`
4. 集合（set）：`sadd name value`，Redis的set是string类型的无序集合；集合是通过哈希表实现的，所以添加、删除、查找的复杂度都是O(1)；
5. 有序集合（zset）：`zadd name score value`，zset和set一样也是string类型元素的集合，且不允许重复的成员；不同的是每个元素都会关联一个double类型的分数，redis正是通过分数来为集合中的成员进行从小到大的排序，zset的成员是唯一的，但分数却可以重复。

## 2. Redis中的内存划分？

1. 数据：作为数据库，数据是最主要的部分；这部分占用的内存会统计在info命令输出的used_memory指标中；Redis使用键值对存储数据，其中的值包括5种类型，这5种类型是redis对外提供的，实际上，在Redis内部，每种类型可能有2种或更多的内部编码实现；此外，Redis在存储对象时，并不是直接将数据扔进内存，而是会对对象进行各种包装：如redisObject、SDS等；
2. 进程本身运行需要的内存：如代码、常量池等等；这部分内存大约几兆，在大多数生产环境中与Redis数据占用相比可以忽略，这部分内存不是由jemalloc分配器分配，因此不会统计在used_memory中；
3. 缓冲内存：如客户端缓冲区、复制积压缓冲区、AOF缓冲区等；
4. 内存碎片：在Redis进行分配、回收物理内存过程中产生，例如，对数据的更改频繁，而数据之间的大小相差很大，可能导致redis释放的空间在物理内存中并没有释放，但redis又无法有效利用，就形成了内存碎片，内存碎片不会统计在used_memory中。

## 3. Redis高可用？

在web服务器中，高可用是指服务器可以正常访问的时间，衡量的标准是在多长时间内可以提供正常服务(99.9%，99.99%，99.999%等等)。在Redis中，高可用除了保证提供正常服务，还需要考虑数据容量扩展、数据安全不会丢失等。主要技术包括：

1. 持久化：主要作用是数据备份，即将数据存储在硬盘，保证数据不会因进程退出而丢失；
2. 复制：复制是高可用redis的基础，哨兵和集群都是在复制基础上实现高可用的。复制主要实现了数据的多机备份，以及对于读操作的负载均衡和简单的故障恢复。缺陷：故障恢复无法自动化；写操作无法负载均衡；存储能力受到单机的限制；
3. 哨兵：在复制的基础上，哨兵实现了自动化的故障恢复。缺陷：写操作无法负载均衡；存储能力受到单机限制；
4. 集群：通过集群，redis解决了写操作无法负载均衡，以及存储能力受到单机限制的问题，实现了较为完善的高可用方案。

## 4. Redis持久化及方式？

Redis是内存数据库，数据都是存储在内存中，为避免进程退出导致数据的永久丢失，定期将redis中的数据以某种形式（数据或命令）从内存保存到硬盘；当redis下次重启时，利用持久化文件实现数据恢复，除此之外，为了进行灾难备份，可以将持久化文件拷贝到一个远程位置。Redis持久化分为如下两种方式：

**RDB持久化**

将当前数据保存到硬盘。将当前进程中的数据生成快照保存到硬盘(因此也称作快照持久化)，保存的文件后缀是rdb；当redis重启时，可以读取快照文件恢复数据。触发命令：`save`和`bgsave`

- save：会阻塞redis服务器进程，直到rdb文件创建完毕为止，在redis服务器阻塞期间，服务器不能处理任何命令请求；已基本被废弃，线上环境杜绝save的使用；
- bgsave：会创建一个子进程，由子进程来负责创建rdb文件，父进程(redis主进程)则继续处理请求，只有在fork子进程时会阻塞服务器；

触发方式：

- 手动触发：命令行执行save和bgsave命令可以触动rdb文件创建；

- 自动触发：在redis的配置文件配置`save m n`，指定当m秒内发生n次变化时，会触发bgsave；当配置有多个save条件时，满足任意一个时都会引起bgsave；
  **save m n**的实现原理：Redis的save m n，是通过serverCron函数、dirty计数器、和lastsave时间戳来实现的。

  serverCron是Redis服务器的周期性操作函数，默认每隔100ms执行一次；该函数对服务器的状态进行维护，其中一项工作就是检查 save m n 配置的条件是否满足，如果满足就执行bgsave。

  dirty计数器是Redis服务器维持的一个状态，记录了上一次执行bgsave/save命令后，服务器状态进行了多少次修改(包括增删改)；而当save/bgsave执行完成后，会将dirty重新置为0。

  例如，如果Redis执行了set mykey helloworld，则dirty值会+1；如果执行了sadd myset v1 v2 v3，则dirty值会+3；注意dirty记录的是服务器进行了多少次修改，而不是客户端执行了多少修改数据的命令。

  lastsave时间戳也是Redis服务器维持的一个状态，记录的是上一次成功执行save/bgsave的时间。

  save m n的原理如下：每隔100ms，执行serverCron函数；在serverCron函数中，遍历save m n配置的保存条件，只要有一个条件满足，就进行bgsave。对于每一个save m n条件，只有下面两条同时满足时才算满足：

  （1）当前时间-lastsave > m

  （2）dirty >= n
  **其他自动触发机制**：主从复制场景下，如果从节点执行全量复制操作，则主节点会执行bgsave命令，并将rdb文件发送给从节点；执行shutdown命令时，自动执行rdb持久化。

bgsave命令的执行流程：

1. Redis父进程首先判断：当前是否在执行save，或bgsave/bgrewriteaof（后面会详细介绍该命令）的子进程，如果在执行则bgsave命令直接返回。bgsave/bgrewriteaof 的子进程不能同时执行，主要是基于性能方面的考虑：两个并发的子进程同时执行大量的磁盘写操作，可能引起严重的性能问题。

2. 父进程执行fork操作创建子进程，这个过程中父进程是阻塞的，Redis不能执行来自客户端的任何命令

3. 父进程fork后，bgsave命令返回”Background saving started”信息并不再阻塞父进程，并可以响应其他命令

4. 子进程创建RDB文件，根据父进程内存快照生成临时快照文件，完成后对原有文件进行原子替换

5. 子进程发送信号给父进程表示完成，父进程更新统计信息

常用配置选项：

- save m n：bgsave自动触发的条件；如果没有save m n配置，相当于自动的rdb持久化关闭，不过此时仍可以通过其他方式触发；
- stop-writes-on-bgsave-error yes：当bgsave出现错误时，Redis是否停止执行写命令；设置为yes，则当硬盘出现问题时，可以及时发现，避免数据的大量丢失；设置为no，则Redis无视bgsave的错误继续执行写命令，当对Redis服务器的系统(尤其是硬盘)使用了监控时，该选项考虑设置为no；
- rdbcompression yes：是否开启RDB文件压缩，默认采用LZF算法对RDB文件进行压缩。虽然压缩耗时，但是可以大大减小RDB文件的体积，因此压缩默认开启，需要注意的是，RDB文件的压缩并不是针对整个文件进行的，而是对数据库中的字符串进行的，且只有在字符串达到一定长度(20字节)时才会进行；
- rdbchecksum yes：是否开启RDB文件的校验，在写入文件和读取文件时都起作用；关闭checksum在写入文件和启动文件时大约能带来10%的性能提升，但是数据损坏时无法发现；
- dbfilename dump.rdb：RDB文件名；
- dir ./：RDB文件和AOF文件所在目录；

**AOF持久化**

将每次执行的写命令保存到硬盘，由于持久化的实时性更好，是目前主流的持久化方式；当redis重启时再次执行AOF文件中的命令来恢复数据。

开启AOF

Redis服务器默认开启RDB，关闭AOF；要开启AOF，需要在配置文件中配置：appendonly yes

执行流程

因为需要记录redis的每条写命令，因此AOF不需要触发，下面介绍AOF执行流程：

- 命令追加(append)
  将redis的写命令追加到缓冲区aof_buf，而不是直接写入文件，主要是为了避免每次有写命令都直接写入硬盘，导致硬盘IO成为redis负载的瓶颈；

- 文件写入(write)和文件同步(sync)
  redis提供了多种AOF缓存区的同步文件策略，策略涉及到操作系统的write函数和fsync函数，说明如下：
  为了提高文件写入效率，在现代操作系统中，当用户调用write函数将数据写入文件时，操作系统通常会将数据暂存到一个内存缓冲区里，当缓冲区被填满或超过了指定时限后，才真正将缓冲区的数据写入到硬盘里。这样的操作虽然提高了效率，但也带来了安全问题：如果计算机停机，内存缓冲区中的数据会丢失；因此系统同时提供了fsync、fdatasync等同步函数，可以强制操作系统立刻将缓冲区中的数据写入到硬盘里，从而确保数据的安全性。
  AOF缓存区的同步文件策略由参数appendfsync控制，各个值的含义如下：

  - always：命令写入aof_buf后立即调用系统fsync操作同步到AOF文件，fsync完成后线程返回。这种情况下，每次有写命令都要同步到AOF文件，硬盘IO成为性能瓶颈，Redis只能支持大约几百TPS写入，严重降低了Redis的性能；即便是使用固态硬盘（SSD），每秒大约也只能处理几万个命令，而且会大大降低SSD的寿命。
  - no：命令写入aof_buf后调用系统write操作，不对AOF文件做fsync同步；同步由操作系统负责，通常同步周期为30秒。这种情况下，文件同步的时间不可控，且缓冲区中堆积的数据会很多，数据安全性无法保证。
  - everysec：命令写入aof_buf后调用系统write操作，write完成后线程返回；fsync同步文件操作由专门的线程每秒调用一次。**everysec是前述两种策略的折中，是性能和数据安全性的平衡，因此是Redis的默认配置，也是我们推荐的配置。**

- 文件重写(rewrite)
  随着时间流逝，Redis服务器执行的写命令越来越多，AOF文件也会越来越大；过大的AOF文件不仅会影响服务器的正常运行，也会导致数据恢复需要的时间过长。

  文件重写是指定期重写AOF文件，减小AOF文件的体积。需要注意的是，**AOF重写是把Redis进程内的数据转化为写命令，同步到新的AOF文件；不会对旧的AOF文件进行任何读取、写入操作!**

  关于文件重写需要注意的另一点是：对于AOF持久化来说，文件重写虽然是强烈推荐的，但并不是必须的；即使没有文件重写，数据也可以被持久化并在Redis启动的时候导入；因此在一些实现中，会关闭自动的文件重写，然后通过定时任务在每天的某一时刻定时执行。

  文件重写之所以能够压缩AOF文件，原因在于：

  - 过期的数据不再写入文件
  - 无效的命令不再写入文件：如有些数据被重复设值(set mykey v1, set mykey v2)、有些数据被删除了(sadd myset v1, del myset)等等
  - 多条命令可以合并为一个：如sadd myset v1, sadd myset v2, sadd myset v3可以合并为sadd myset v1 v2 v3。不过为了防止单条命令过大造成客户端缓冲区溢出，对于list、set、hash、zset类型的key，并不一定只使用一条命令；而是以某个常量为界将命令拆分为多条。这个常量在redis.h/REDIS_AOF_REWRITE_ITEMS_PER_CMD中定义，不可更改，3.0版本中值是64。

  通过上述内容可以看出，由于重写后AOF执行的命令减少了，文件重写既可以减少文件占用的空间，也可以加快恢复速度。
  **文件重写的触发**

  - 手动触发：直接调用bgwriteaof命令，与bgsave有些类似，都是fork子进程进行具体的工作，且都只在fork时阻塞；
  - 自动触发：根据auto-aof-rewrite-min-size和auto-aof-rewrite-percentage参数，以及aof_current_size和aof_base_size状态确定触发时机；
    auto-aof-rewrite-min-size：执行AOF重写时，文件的最小体积，默认值为64MB。
    auto-aof-rewrite-percentage：执行AOF重写时，当前AOF大小(即aof_current_size)和上一次重写时AOF大小(aof_base_size)的比值；
    只有当auto-aof-rewrite-min-size和auto-aof-rewrite-percentage两个参数同时满足时，才会自动触发AOF重写，即bgrewriteaof操作。

  **文件重写流程**

  1. Redis父进程首先判断当前是否存在正在执行 bgsave/bgrewriteaof的子进程，如果存在则bgrewriteaof命令直接返回，如果存在bgsave命令则等bgsave执行完成后再执行。前面曾介绍过，这个主要是基于性能方面的考虑。
  2. 父进程执行fork操作创建子进程，这个过程中父进程是阻塞的。
  3. 父进程fork后，bgrewriteaof命令返回”Background append only file rewrite started”信息并不再阻塞父进程，并可以响应其他命令。**Redis的所有写命令依然写入AOF缓冲区，并根据appendfsync策略同步到硬盘，保证原有AOF机制的正确。**
  4. 由于fork操作使用写时复制技术，子进程只能共享fork操作时的内存数据。**由于父进程依然在响应命令，因此Redis使用AOF重写缓冲区(aof_rewrite_buf)保存这部分数据，防止新AOF文件生成期间丢失这部分数据。也就是说，bgrewriteaof执行期间，Redis的写命令同时追加到aof_buf和aof_rewirte_buf两个缓冲区。**
  5. 子进程根据内存快照，按照命令合并规则写入到新的AOF文件。
  6. 子进程写完新的AOF文件后，向父进程发信号，父进程更新统计信息，具体可以通过info persistence查看。
  7. 父进程把AOF重写缓冲区的数据写入到新的AOF文件，这样就保证了新AOF文件所保存的数据库状态和服务器当前状态一致。
  8. 使用新的AOF文件替换老文件，完成AOF重写。

  常用配置选项：

  - appendonly no：是否开启AOF
  - appendfilename "appendonly.aof"：AOF文件名
  - dir ./：RDB文件和AOF文件所在目录
  - appendfsync everysec：fsync持久化同步策略
  - no-appendfsync-on-rewrite no：AOF重写期间是否禁止fsync；如果开启该选项，可以减轻文件重写时CPU和硬盘的负载（尤其是硬盘），但是可能会丢失AOF重写期间的数据；需要在负载和安全性之间进行平衡
  - auto-aof-rewrite-percentage 100：文件重写触发条件之一
  - auto-aof-rewrite-min-size 64mb：文件重写触发提交之一
  - aof-load-truncated yes：如果AOF文件结尾损坏，Redis启动时是否仍载入AOF文件

## 5. RDB和AOF的优缺点？

- RDB
  - 优点：RDB文件紧凑，体积小，网络传输快，适合全量复制；恢复速度比AOF快很多；与AOF相比，最重要的有点之一是对性能的影响相对较小；
  - 缺点：RDB文件在于其数据快照的持久化方式决定了必然做不到实时持久化，数据的大量丢失很多时候是无法接受的；此外RDB文件需要满足特定格式，兼容性差；
- AOF
  - 优点：支持秒级持久化、兼容性好
  - 缺点：文件大、恢复速度慢、对性能影响大

无论是RDB还是AOF，持久化的开启都是要付出性能方面代价的：对于RDB持久化，一方面是bgsave在进行fork操作时Redis主进程会阻塞，另一方面，子进程向硬盘写数据也会带来IO压力；对于AOF持久化，向硬盘写数据的频率大大提高(everysec策略下为秒级)，IO压力更大，甚至可能造成AOF追加阻塞问题，此外，AOF文件的重写与RDB的bgsave类似，会有fork时的阻塞和子进程的IO压力问题。相对来说，由于AOF向硬盘中写数据的频率更高，因此对Redis主进程性能的影响会更大。

## 6. 持久化过程中的阻塞问题？

**fork阻塞：cpu阻塞**

fork操作：父进程通过fork操作可以创建子进程；子进程创建后，父子进程共享代码段，不共享进程的数据空间，但是子进程会获得父进程的数据空间的副本。在操作系统fork的实际实现中，基本都采用了写时复制技术，即在父/子进程试图修改数据空间之前，父子进程实际上共享数据空间；但是当父/子进程的任何一个试图修改数据空间时，操作系统会为修改的那一部分(内存的一页)制作一个副本。虽然fork时，子进程不会复制父进程的数据空间，但是会复制内存页表（页表相当于内存的索引、目录）；父进程的数据空间越大，内存页表越大，fork时复制耗时也会越多。

在Redis中，无论是RDB持久化的bgsave，还是AOF重写的bgrewriteaof，都需要fork出子进程来进行操作。如果Redis内存过大，会导致fork操作时复制内存页表耗时过多；而Redis主进程在进行fork时，是完全阻塞的，也就意味着无法响应客户端的请求，会造成请求延迟过大。

对于不同的硬件、不同的操作系统，fork操作的耗时会有所差别，一般来说，如果Redis单机内存达到了10GB，fork时耗时可能会达到百毫秒级别（如果使用Xen虚拟机，这个耗时可能达到秒级别）。因此，一般来说Redis单机内存一般要限制在10GB以内；不过这个数据并不是绝对的，可以通过观察线上环境fork的耗时来进行调整。

观察的方法如下：执行命令info stats，查看latest_fork_usec的值，单位为微秒。为了减轻fork操作带来的阻塞问题，除了控制Redis单机内存的大小以外，还可以适度放宽AOF重写的触发条件、选用物理机或高效支持fork操作的虚拟化技术等，例如使用Vmware或KVM虚拟机，不要使用Xen虚拟机。

**AOF追加阻塞：硬盘的阻塞**

在AOF中，如果AOF缓冲区的文件同步策略为everysec，则：在主线程中，命令写入aof_buf后调用系统write操作，write完成后主线程返回；fsync同步文件操作由专门的文件同步线程每秒调用一次。

这种做法的问题在于，如果硬盘负载过高，那么fsync操作可能会超过1s；如果Redis主线程持续高速向aof_buf写入命令，硬盘的负载可能会越来越大，IO资源消耗更快；如果此时Redis进程异常退出，丢失的数据也会越来越多，可能远超过1s。

为此，Redis的处理策略是这样的：主线程每次进行AOF会对比上次fsync成功的时间；如果距上次不到2s，主线程直接返回；如果超过2s，则主线程阻塞直到fsync同步完成。因此，如果系统硬盘负载过大导致fsync速度太慢，会导致Redis主线程的阻塞；此外，使用everysec配置，AOF最多可能丢失2s的数据，而不是1s。

AOF追加阻塞问题定位的方法：

（1）监控info Persistence中的aof_delayed_fsync：当AOF追加阻塞发生时（即主线程等待fsync而阻塞），该指标累加。

（2）AOF阻塞时的Redis日志：Asynchronous AOF fsync is taking too long (disk is busy?). Writing the AOF buffer without waiting for fsync to complete, this may slow down Redis.

（3）如果AOF追加阻塞频繁发生，说明系统的硬盘负载太大；可以考虑更换IO速度更快的硬盘，或者通过IO监控分析工具对系统的IO负载进行分析，如iostat（系统级io）、iotop（io版的top）、pidstat等。

## 7. redis有哪些架构模式？各自的特点

- 单击版：简单
  缺陷：1. 内存容量有限；2. 处理能力有限；3. 无法高可用

- 主从复制：redis的复制功能允许用户根据一个redis服务器来创建任意多个该服务器的复制品，互为主从节点，主服务器会一直将发生在自己身上的数据更新同步给从服务器，从而一直保证主从服务器的数据相同；
  特点：1. master/slave角色；2. master/slave数据相同；3. 降低master读压力
  缺陷：无法解决master的写负载均衡；故障无法自动恢复；存储能力受到单机限制

- 哨兵：保证高可用；监控各个节点；自动故障迁移
  缺陷：无法实现写负载均衡；存储能力受到单机限制

- 集群：redis3.0之后版本支持redis-cluster集群，采用无中心结构，每个节点保存数据和整个集群状态，每个节点都和其他所有节点连接；
  特点：

  1. 无中心架构；
  2. 数据按照slot存储分布在多个节点，节点间数据共享，可动态调整数据分布；
  3. 可扩展性，可线性扩展到1000个节点，节点可动态添加或删除；
  4. 高可用性，部分节点不可以时，集群仍可用
  5. 实现故障自动failover，节点之间通过gossip协议交换状态信息，用投票机制完成slave到master的角色提升；

  缺点：

  1. 数据通过主从异步复制，不保证数据的强一致性

## 8. redis常用命令？

1. keys pattern：匹配指定模式的key，\*表示所有；
2. exists key：key是否存在；
3. set key value：设置key对应的值为string类型的value；
4. setnx key value：设置key对应的值为string类型的value，如果key已经存在，返回0，nx是not exist的意思；
5. del key：删除某个key，第一次返回1，删除了，第二次返回0；
6. expire：设置过期时间；
7. ttl：查看剩下多少时间；返回负数则key失效，key不存在了；
8. setex：设置key对应的值为string类型的value，并指定此键值对应的有效期；
9. mset：一次设置多个key的值，成功返回ok表示所有的值都设置了，失败返回0表示没有任何值被设置；
10. getset：设置key的值，并返回key的旧值；
11. mget：一次获取多个key的值

## 9. 什么是缓存穿透？如何避免？

对于系统A，假设一秒5000个请求，结果其中4000个请求是黑客发出的恶意攻击，黑客发出的那4000个攻击，缓存中查不到，每次你去数据库里查，也查不到。比如：数据库id是从1开始的，结果黑客发过来的请求id全部都是负数。这样的话，缓存中不会有，请求每次都视缓存于无物，直接查询数据库。这种恶意攻击场景的缓存穿透就会直接把数据库给打死。

解决方案：

- 每次系统从数据库中只要没查到，就写一个空值到缓存里去，这样的话下次便能走缓存了。

## 10. 什么是缓存雪崩？

对于一个系统，缓存机器意外发生了全盘宕机，缓存挂了，此时所有的请求全部落数据库，数据库必然扛不住，它会报一下警，然后就挂了。此时，如果没用什么特别的方案来处理这个故障，DBA很着急，重启数据库，但是数据库立马又被新的流量给打死了。这就是缓存雪崩。

解决方案：

- 事前：redis高可用，主从+哨兵，redis cluster，避免全盘崩溃；
- 事中：本地encache缓存+hystrix限流&降级，避免MySQL被打死；
- 事后：redis持久化，一旦重启，自动从磁盘上加载数据，快速恢复缓存数据。

用户发送一个请求，系统A收到请求后，先查本地ehcache缓存，如果没查到再查redis。如果ehcache和redis都没有，再查数据库，将数据库中的结果，写入ehcache和redis中；

限流组件，可以设置每秒的请求，有多少能通过组件，剩余的未通过的请求，怎么办？走降级，可以返回一些默认的值，或者友情提示，或者空白的值。

好处：

- 数据库绝对不会死，限流组件确保了每秒只有多少个请求能通过；
- 只要数据库不死，就是说，对用户来说，2/5的请求都是可以被处理的；
- 只要有2/5的请求可以被处理，就意味这你的系统没死，对用户来说，可能就是点击几次刷不出来页面，但是多点几次就可以刷出来一次。

## 11. 为什么要用缓存？

1. 首先我们的数据基本是通过定时任务每日计算刷新的，也就是说一旦定时任务更新完毕，在一天之内数据不会发生改变；
2. 缓存存放在内存里面，每次查询的时候不需要访问mysql数据库，可以比mysql数据库提供更好的访问性能；
3. 缓存具有更高的并发性。

## 12. 缓存带来的问题？

1. 缓存与数据库双写不一致；
2. 缓存雪崩、缓存穿透
3. 缓存并发竞争



## 13. redis的过期策略有哪些？

过期策略是：定期删除+惰性删除。

定期删除：指redis默认是每隔100ms就随机抽取一些设置了过期时间的key，检查其是否过期，如果过期就删除；假设redis里放了10w个key，都设置了过期时间，你每隔几百毫秒，就检查10w个key，那redis基本上就死了，cpu负载会很高，消耗在你的检查过期key上了。注意，这里可不是每隔100ms就遍历所有的设置过期时间的key，那样就是一场性能上的灾难。实际上redis是每隔100ms**随机抽取**一些key来检查和删除的。

但是问题是，定期删除可能会导致很多过期key到了时间并没有被删除掉，那咋整？所以就是惰性删除了。也就是说，**在你获取某个key的时候，redis会检查一下，这个key如果设置了过期时间那么是否过期了？如果过期了此时就会删除，不会给你返回任何东西**。

但是这依然会有问题，如果定期删除漏掉了很多过期key，然后你也没及时去查，也就没走惰性删除，此时会怎样？如果大量过期key堆积在内存里，导致redis内存块耗尽了，怎么办？这就涉及到**内存淘汰机制**。

## 14. redis的内存淘汰机制？

- noeviction：当内存不足以容纳新写入数据时，新写入操作会报错，这个一般没人用；
- allkeys-lru：当内存不足以容纳新写入数据时，在键空间中，移除最近最少使用的key(这个是最常用的)；
- allkeys-random：当内存不足以容纳新写入数据时，在键空间中，随机移除某个key，这个一般没人用；
- volatile-lru：当内存不足以容纳新写入数据时，在设置了过期时间的键空间中，移除最近最少使用的key(这个一般不太合适)；
- volatile-random：当内存不足以容纳新写入数据时，在设置了过期时间的键空间中，随机移除某个key；
- volatile-ttl：当内存不足以容纳新写入数据时，在设置了过期时间的键空间中，有更早过期时间的key优先移除。

## 15. 手写一个LRU算法？

## 16.如何保证redis的高并发和高可用？

redis实现高并发主要依靠主从架构，一主多从，一般来说很多项目其实就足够了，单主用来写入数据，单机几万QPS，多从用来查询数据，多个从实例可以提供每秒10w的QPS。

如果在实现高并发的同时，要容纳大量的数据，就需要redis集群，使用redis集群之后，可以提供每秒几十万的读写并发。

如果是主从架构的高可用，那么加上哨兵就可以实现，任何一个实例宕机可以进行主备切换。

## 17. redis主从架构？

单机的redis能够承载的QPS大概就在上万到几万不等。对于缓存来说，一般都是用来支撑读高并发的。因此架构做成主从架构，一主多从，主负责写，并且将数据复制到其它的slave节点，从节点负责读。所有的读请求全部走从节点。这样也可以实现水平扩容，支撑读高并发。

主从复制的核心机制：

- redis采用异步方式复制数据到slave节点，从2.8版本开始，slave node会周期性的确认自己每次复制的数据量；
- 一个master node可以有多个slave，但一个slave在同一时刻只能有一个master；
- slave节点可以连接其他的slave节点；
- slave做复制的时候不会阻塞master的正常工作；
- slave做复制时也不会阻塞自己的查询操作，它会用旧数据来提供服务；但是复制完成的时候需要删除旧数据集，加载新数据集，这个时候就会暂停对外服务了；
- slave主要用来进行横向扩容，做读写分离，扩容的slave可以提高读的吞吐量。

如果采用了主从架构，建议必须开启master节点的持久化，不建议用slave作为master的数据热备，因为如果关掉master的持久化，可能在master宕机重启的时候数据是空的，然后可能一经过复制，slave的数据也丢了。

master的各种备份方案也需要做，万一本地的所有文件丢失了，从备份中挑选一份rdb去恢复master，这样才能确保启动的时候是有数据的，即使采用了后续讲解的高可用机制，slave可以自动接管master，但也可能sentinel还没检测到master failure，master就自动重启了，还是可能导致上面所有的slave数据清空。

## 18. redis主从复制的核心原理？

主从复制的作用：

1. 数据冗余：主从复制实现了数据的热备份，是持久化之外的一种数据冗余方式；
2. 故障恢复：当主节点出现问题时，可以由从节点提供服务，实现快速的故障恢复；
3. 负载均衡：在主从复制的基础上，配合读写分离，可以由主节点提供写服务，由从节点提供读服务，分担服务器负载；
4. 高可用基石：是哨兵和集群能够实施的基础。

**原理**

1. **连接建立阶段：**在主从节点之间建立连接，为数据同步做好准备，有从节点发起

   - 保存主节点信息：从节点服务器内部维护了masterhost和masterport用于存储主节点的ip和port；需要注意slaveof是异步命令，从节点完成主节点ip和port保存后，向发送slaveof命令的redis-cli客户端直接返回ok，实际的复制操作在这之后才开始进行；

   - 建立socket连接：从节点每秒一次调用复制函数replicationCron()，如果发现有主节点可以连接，便会根据主节点ip和port创建socket连接；连接成功，执行如下步骤：

     - 从节点：为该socked建立一个专门处理复制的文件事件处理器，负责后续的复制工作，如接受rdb文件、接受命令传播等；
     - 主节点：接收从节点的socket连接后，为该socket创建相应的客户端状态，并将从节点看作是连接到主节点的一个客户端，后面的步骤会以从节点向主节点发送命令请求的形式来进行

   - 发送ping命令：从节点成为主节点客户端后，发送ping命令进行首次请求，目的是：检查socket连接是否可用，以及主节点当前是否能够处理请求；可能出现3中结果：

     - 返回pong：说明socket连接正常，且主节点当前可以处理请求，复制过程继续；
     - 超时：一定时间后从节点仍未收到主节点回复，说明socket连接不可用，则从节点断开socket连接，并重连；
     - 返回pong以外的结果：如果主节点返回其他结果，如正在处理超时运行脚本，说明主节点当前无法处理命令，则从节点断开socket连接，并重连

   - 身份验证：如果从节点中设置了masterauth选项，则从节点需要向主节点进行身份验证；没有设置该选项，则不需要验证。从节点进行身份验证是通过向主节点发送auth命令进行的，auth命令的参数即为配置文件中的masterauth的值。

     如果主节点设置密码的状态，与从节点masterauth的状态一致（一致是指都存在，且密码相同，或者都不存在），则身份验证通过，复制过程继续；如果不一致，则从节点断开socket连接，并重连。

   - 发送从节点端口信息：身份验证之后，从节点会向主节点发送其监听的端口号，主节点将该信息保存到该从节点对应的客户端的slave_listening_port字段中；该端口信息除了在主节点中执行info Replication时显示以外，没有其他作用。

2. **数据同步阶段：**主从节点连接建立之后，便可以开始进行数据同步，该阶段可以理解为从节点数据的初始化，具体执行方式是：从节点向主节点发送psync命令，开始同步；

   - 全量复制：从节点通过发送psync命令请求同步数据，用于初次复制或其他无法进行部分复制的情况，将主节点的所有数据都发送给从节点，是一个非常重型的操作。过程如下：

     - 从节点判断无法进行部分复制，像主节点发送全量复制的请求；或从节点发送部分复制请求，但主节点判断无法进行部分复制；
     - 主节点接收到全量复制命令后，执行bgsave，在后台生成rdb文件，并使用**复制缓冲区**记录从现在开始执行的所有写命令；
     - 主节点的bgsave执行完成后，将rdb文件发送给从节点；从节点首先清除自己的旧数据，然后载入接收的rdb文件，将数据库状态更新至主节点执行bgsave时的数据状态；
     - 主节点将前述复制缓冲区中的所有写命令发送给从节点，从节点执行这些写命令，将数据状态更新至主节点的最新状态；
     - 如果从节点开启了AOF，则会触发bgwriteaof的执行，从而保证AOF文件更新至主节点的最新状态

     全量复制是非常重型的操作：

     1. 主节点通过bgsave命令fork子进程进行rdb持久化，该过程非常消耗cpu、内存(页表复制)、硬盘IO；
     2. 主节点通过网络将rdb文件发送给从节点，对主节点的带宽都会带来很大的消耗；
     3. 从节点清空老数据、载入新RDB文件的过程是阻塞的，无法响应客户端的命令；如果从节点执行bgwriteof，也会带来额外的消耗。

   - 部分复制：由于全量复制在主节点数据量大时效率太低，因此2.8版本之后提供部分复制用于处理网络中断时的数据同步。三个重要概念：

     1. 复制偏移量：主节点和从节点分别维护一个复制偏移量，代表的是主节点向从节点传递的字节数；主节点每次向从节点传播N个字节数据时，主节点的offset增加N；从节点每次收到主节点传来的N个字节数据时，从节点的offset增加N；offset用于判断主从节点的数据状态是否有丢失；
     2. 复制积压缓冲区：由主节点维护的、固定长度的、FIFO队列，默认大小1MB；当主节点开始有从节点时创建，用于备份主节点最近发送给从节点的数据。无论有多少个从节点，都只需要一个复制积压缓冲区。在命令传播阶段时，主节点除了将写命令发送给从节点，还会发送一份到复制积压缓冲区，作为写命令备份，除了存储写命令，复制积压缓冲区中还存储了其中的每个字节对应的复制偏移量（offset）。由于复制积压缓冲区定长且是先进先出，所以它保存的是主节点最近执行的写命令；时间较早的写命令会被挤出缓冲区。**由于该缓冲区长度固定且有限，因此可以备份的写命令也有限，当主从节点offset的差距过大超过缓冲区长度时，将无法执行部分复制，只能执行全量复制**。反过来说，为了提高网络中断时部分复制执行的概率，可以根据需要增大复制积压缓冲区的大小(通过配置repl-backlog-size)；例如如果网络中断的平均时间是60s，而主节点平均每秒产生的写命令(特定协议格式)所占的字节数为100KB，则复制积压缓冲区的平均需求为6MB，保险起见，可以设置为12MB，来保证绝大多数断线情况都可以使用部分复制。
        从节点将offset发送给主节点后，主节点根据offset和缓冲区大小决定能否执行部分复制：
        - 如果offset偏移量之后的数据，仍然都在复制积压缓冲区里，则执行部分复制；
        - 如果offset偏移量之后的数据已不在复制积压缓冲区，则执行全量复制。
     3. 服务器运行ID：每个Redis节点(无论主从)，在启动时都会自动生成一个随机ID(每次启动都不一样)，由40个随机的十六进制字符组成；runid用来唯一识别一个Redis节点。主从节点初次复制时，主节点将自己的runid发送给从节点，从节点将这个runid保存起来；当断线重连时，从节点会将这个runid发送给主节点；主节点根据runid判断能否进行部分复制：
        - 如果从节点保存的runid与主节点现在的runid相同，说明主从节点之前同步过，主节点会继续尝试使用部分复制(到底能不能部分复制还要看offset和复制积压缓冲区的情况)；
        - 如果从节点保存的runid与主节点现在的runid不同，说明从节点在断线前同步的Redis节点并不是当前的主节点，只能进行全量复制。

   - psync命令的执行过程

     1. 首先，从节点根据当前状态，决定如何调用psync命令：
        - 如果从节点之前未执行过slaveof或最近执行了slaveof no one，则从节点发送命令为psync ？ -1，向主节点请求全量复制；
        - 如果从节点之前执行过slaveof，则发送命令psync <runid\> <offset\>，其中runid为上次复制的主节点的runid，offset为上次复制截止时从节点保存的复制偏移量；
     2. 主节点根据收到的psync命令，及当前服务器状态，决定执行全量复制还是部分复制：
        - 如果主节点版本低于2.8，则返回-ERR回复，此时从节点重新发送sync命令执行全量复制；
        - 如果主节点版本够新，且runid与从节点发送的runid相同，且从节点发送的offset之后的数据在复制积压缓冲区中都存在，则回复+CONTINUE，表示将进行部分复制，从节点等待主节点发送其缺少的数据即可；
        - 如果主节点版本够新，但是runid与从节点发送的runid不同，或从节点发送的offset之后的数据已不在复制积压缓冲区中(在队列中被挤出了)，则回复+FULLRESYNC <runid\> <offset\>，表示要进行全量复制，其中runid表示主节点当前的runid，offset表示主节点当前的offset，从节点保存这两个值，以备使用。

3. **命令传播阶段：**数据同步阶段完成后，主从节点进入命令传播阶段，在这个阶段主节点将自己执行的写命令发送给从节点，从节点接收命令并执行，从而保证主从节点数据的一致性。
   在命令传播阶段，除了发送写命令，主从节点还维持这心跳机制：PING和REPLCONF ACK。由于心跳机制的原理涉及部分复制，因此将在介绍了部分复制的相关内容后单独介绍该心跳机制。
   心跳机制：

   - PING：每隔指定的时间，主节点会向从节点发送PING命令，用于从节点进行超时判断；PING命令的发送频率有repl-ping-slave-period参数进行控制，单位是秒，默认10s；
   - REPLCONF ACK：从节点会向主节点发送REPLCONF ACK命令，频率是每秒1次；命令格式为：REPLCONF ACK {offset}，其中offset指从节点保存的复制偏移量。REPLCONF ACK命令的作用有：
     - 实时监测主从节点网络状态：该命令会被主节点用于复制超时的判断。此外，在主节点中使用info replication，可以看到其从节点的状态中的lag值，代表的是主节点上次收到该REPLCONF ACK命令的时间间隔，在正常情况下，该值应该是0或1；
     - 检测命令丢失：从节点发送了自身的offset，主节点会与自己的offset对比，如果从节点数据缺失(如网络丢包)，主节点会推送缺失的数据(这里也会利用复制积压缓冲区)。注意，offset和复制积压缓冲区不仅可以用于部分复制，也可以用于处理命令丢失等情形；区别在于前者是在断线重连后进行的，而后者是在主从节点没有断线的情况下进行的；
     - 辅助保证从节点的数量和延迟：redis主节点中使用min-slaves-to-write和min-slaves-max-lag参数，来保证主节点在不安全的情况下不会执行写命令；所谓不安全，是指从节点数量太少或延迟过高。例如min-slaves-to-write和min-slaves-max-lag分别是3和10，含义是如果从节点数量小于3个，或所有从节点的延迟值都大于10s，则主节点拒绝执行写命令。而这里从节点延迟值的获取，就是通过主节点接收到REPLCONF ACK命令的时间来判断的，即前面所说的info Replication中的lag值。

## 19. 主从复制中的问题？

**延迟与不一致问题**

由于主从复制的命令传播是异步的，延迟与数据的不一致不可避免。如果应用对数据不一致的接受程度较低，可能的优化措施包括：优化主从节点之间的网络环境(如在同机房部署)；监控主从节点延迟(通过offset)判断，如果从节点延迟过大，通知应用不再通过从节点读取数据；使用集群同时扩展写负载和读负载等。

在命令传播阶段以外的其他情况下，从节点的数据不一致可能更加严重，例如连接在数据同步阶段，或从节点失去与主节点的连接时等。从节点的slave-serve-stale-data参数便与此有关：它控制这种情况下从节点的表现；如果为yes（默认值），则从节点仍能够响应客户端的命令，如果为no，则从节点只能响应info、slaveof等少数命令。该参数的设置与应用对数据一致性的要求有关；如果对数据一致性要求很高，则应设置为no。

**数据过期问题**

在单机版Redis中，存在两种删除策略，请参考上面写到的过期策略和内存策略：

- 惰性删除：服务器不会主动删除数据，只有当客户端查询某个数据时，服务器判断该数据是否过期，如果过期则删除。
- 定期删除：服务器执行定时任务删除过期数据，但是考虑到内存和CPU的折中（删除会释放内存，但是频繁的删除操作对CPU不友好），该删除的频率和执行时间都受到了限制。

在主从复制场景下，为了主从节点的数据一致性，从节点不会主动删除数据，而是由主节点控制从节点中过期数据的删除。由于主节点的惰性删除和定期删除策略，都不能保证主节点及时对过期数据执行删除操作，因此，当客户端通过Redis从节点读取数据时，很容易读取到已经过期的数据。

Redis 3.2中，从节点在读取数据时，增加了对数据是否过期的判断：如果该数据已过期，则不返回给客户端；将Redis升级到3.2可以解决数据过期问题。

**故障切换问题**

在没有使用哨兵的读写分离场景下，应用针对读和写分别连接不同的Redis节点；当主节点或从节点出现问题而发生更改时，需要及时修改应用程序读写Redis数据的连接；连接的切换可以手动进行，或者自己写监控程序进行切换，但前者响应慢、容易出错，后者实现复杂，成本都不算低。

可以通过引入哨兵解决。

总结：在使用读写分离之前，可以考虑其他方法增加Redis的读负载能力：如尽量优化主节点（减少慢查询、减少持久化等其他情况带来的阻塞等）提高负载能力；使用Redis集群同时提高读负载能力和写负载能力等。如果使用读写分离，可以使用哨兵，使主从节点的故障切换尽可能自动化，并可以减少对应用程序的侵入。

**复制超时问题**

超时判断的意义：

- 如果主节点判断连接超时，其会释放相应从节点的连接，从而释放各种资源，否则无效的从节点仍会占用主节点的各种资源（输出缓冲区、带宽、连接等）；此外连接超时的判断可以让主节点更准确的知道当前有效从节点的个数，有助于保证数据安全（配合前面讲到的min-slaves-to-write等参数）；
- 如果从节点判断连接超时，则可以及时重新建立连接，避免与主节点数据长期的不一致。

判断方式：核心在于repl-timeout参数，该参数规定了超时时间的阈值(默认60s)

- 主节点：每秒调用一次复制定时函数replicationCron()，在其中判断当前时间距离上次收到各个从节点REPLCONF ACK命令的时间是否超过了repl-timeout的值，如果超过了则释放相应从节点的连接；
- 从节点：对超时的判断同样是在复制定时函数中判断，基本逻辑：
  - 如果处于连接建立阶段，且距离上次收到主节点的信息的时间已经超过repl-timeout，则释放与主节点的连接；
  - 如果处于数据同步阶段，且收到主节点的RDB文件的时间超时，则停止数据同步，释放连接；
  - 如果处于命令同步阶段，且距离上次收到主节点的PING命令或数据的时间已超过repl-timeout，则释放与主节点的连接

注意的坑：

1. 数据同步阶段：在主从节点进行全量复制bgsave时，主节点需要首先fork子进程将当前数据保存到RDB文件中，然后再将RDB文件通过网络传输到从节点。如果RDB文件过大，主节点在fork子进程+保存RDB文件时耗时过多，可能会导致从节点长时间收不到数据而触发超时；此时从节点会重连主节点，然后再次全量复制，再次超时，再次重连……这是个悲伤的循环。为了避免这种情况的发生，除了注意Redis单机数据量不要过大，另一方面就是适当增大repl-timeout值，具体的大小可以根据bgsave耗时来调整。
2. 命令传播阶段：如前所述，在该阶段主节点会向从节点发送PING命令，频率由repl-ping-slave-period控制；该参数应明显小于repl-timeout值(后者至少是前者的几倍)。否则，如果两个参数相等或接近，网络抖动导致个别PING命令丢失，此时恰巧主节点也没有向从节点发送数据，则从节点很容易判断超时。
3. 慢查询导致的阻塞：如果主节点或从节点执行了一些慢查询（如keys *或者对大数据的hgetall等），导致服务器阻塞；阻塞期间无法响应复制连接中对方节点的请求，可能导致复制超时。

**复制中断问题**

主从节点超时是复制中断的原因之一，除此之外，还有其他情况可能导致复制中断，其中最主要的是复制缓冲区溢出问题。

在全量复制阶段，主节点会将执行的写命令放到复制缓冲区中，该缓冲区存放的数据包括了以下几个时间段内主节点执行的写命令：bgsave生成RDB文件、RDB文件由主节点发往从节点、从节点清空老数据并载入RDB文件中的数据。当主节点数据量较大，或者主从节点之间网络延迟较大时，可能导致该缓冲区的大小超过了限制，此时主节点会断开与从节点之间的连接；这种情况可能引起全量复制->复制缓冲区溢出导致连接中断->重连->全量复制->复制缓冲区溢出导致连接中断……的循环。

复制缓冲区的大小由client-output-buffer-limit slave {hard limit} {soft limit} {soft seconds}配置，默认值为client-output-buffer-limit slave 256MB 64MB 60，其含义是：如果buffer大于256MB，或者连续60s大于64MB，则主节点会断开与该从节点的连接。该参数是可以通过config set命令动态配置的（即不重启Redis也可以生效）。

**复制优化技巧**

1. 第一次建立复制
   此时全量复制不可避免，但仍有几点需要注意：如果主节点的数据量较大，应该尽量避开流量的高峰期，避免造成阻塞；如果有多个从节点需要建立对主节点的复制，可以考虑将几个从节点错开，避免主节点带宽占用过大。
2. 主节点重启
   - 主节点宕机：宕机重启后，runid会发生变化，因此不能进行部分复制，只能全量复制；实际上在主节点宕机的情况下，应进行故障转移处理，将其中的一个从节点升级为主节点，其他从节点从新的主节点进行复制；
   - 安全重启(debug reload)：在一些场景下，可能希望对主节点进行重启，例如主节点内存碎片率过高，或者希望调整一些只能在启动时调整的参数。如果使用普通的手段重启主节点，会使得runid发生变化，可能导致不必要的全量复制。为了解决这个问题，Redis提供了debug reload的重启方式：**重启后，主节点的runid和offset都不受影响，**避免了全量复制。但debug reload会清空当前内存中的数据，重新从RDB文件中加载，这个过程会导致主节点的阻塞，因此也需要谨慎。
3. 从节点重启
   从节点宕机重启后，其保存的主节点的runid会丢失，因此即使再次执行slaveof，也无法进行部分复制；
4. 网络中断
   - 网络问题时间极为短暂，只造成了短暂的丢包，主从节点都没有判定超时（未触发repl-timeout）；此时只需要通过REPLCONF ACK来补充丢失的数据即可；
   - 网络问题时间很长，主从节点判断超时（触发了repl-timeout），且丢失的数据过多，超过了复制积压缓冲区所能存储的范围；此时主从节点无法进行部分复制，只能进行全量复制。为了尽可能避免这种情况的发生，应该根据实际情况适当调整复制积压缓冲区的大小；此外及时发现并修复网络中断，也可以减少全量复制；
   - 介于前述两种情况之间，主从节点判断超时，且丢失的数据仍然都在复制积压缓冲区中；此时主从节点可以进行部分复制。

**复制相关的配置**

1. 与主从节点都有关的配置
   - slaveof <masterip\> <masterport\>：Redis启动时起作用；作用是建立复制关系，开启了该配置的Redis服务器在启动后成为从节点。该注释默认注释掉，即Redis服务器默认都是主节点；
   - repl-timeout 60：与各个阶段主从节点连接超时判断有关，见前面的介绍。
2. 主节点相关配置
   - repl-diskless-sync no：作用与全量复制阶段，控制主节点是否使用diskless复制(无盘复制)。所谓diskless复制，是指在全量复制时，主节点不再先把数据写入RDB文件，而是直接写入slave的socket中，整个过程中不涉及硬盘；diskless复制在磁盘IO很慢而网速很快时更有优势。截至3.0版本，diskless复制处于实验阶段，默认是关闭的；
   - repl-diskless-sync-delay 5：该配置作用于全量复制阶段，当主节点使用diskless复制时，该配置决定主节点向从节点发送之前停顿的时间，单位是秒；只有当diskless复制打开时有效。之所以设置停顿时间，是基于以下两个考虑：(1)向slave的socket的传输一旦开始，新连接的slave只能等待当前数据传输结束，才能开始新的数据传输 (2)多个从节点有较大的概率在短时间内建立主从复制。
   - client-output-buffer-limit slave 256MB 64MB 60：与全量复制阶段主节点的复制缓冲区大小有关；
   - masterauth <master-passwd\>：与连接建立阶段的身份验证有关；
   - repl-ping-slave-period 10：与命令传播阶段主从节点的超时判断有关；
   - repl-backlog-size 1mb：复制积压缓冲区的大小；
   - repl-disable-tcp-nodelay no：该配置作用于命令传播阶段，控制主节点是否禁止与从节点的TCP_NODELAY；默认no，即不禁止TCP_NODELAY。当设置为yes时，TCP会对包进行合并从而减少带宽，但是发送的频率会降低，从节点数据延迟增加，一致性变差；具体发送频率与Linux内核的配置有关，默认配置为40ms。当设置为no时，TCP会立马将主节点的数据发送给从节点，带宽增加但延迟变小；
   - repl-backlog-ttl 3600：当主节点没有从节点时，复制积压缓冲区保留的时间，这样当断开的从节点重新连进来时，可以进行部分复制；默认3600s，如果设置为0，则永远不会释放复制积压缓冲区；
   - min-slaves-to-write 3与min-slaves-max-lag 10：规定了主节点的最小从节点数目，及应对的最大延迟。
3. 从节点相关配置
   - slave-serve-stale-data yes：与从节点数据陈旧时是否响应客户端命令，前面有介绍；
   - slave-read-only yes：从节点是否只读；默认是只读的。由于从节点开启写操作容易导致主从节点的数据不一致，因此该配置尽量不要修改。

**单机内存的影响**

1. 切主：当主节点宕机时，一种常见的容灾策略是将其中一个从节点提升为主节点，并将其他从节点挂载到新的主节点上，此时这些从节点只能进行全量复制；如果Redis单机内存达到10GB，一个从节点的同步时间在几分钟的级别；如果从节点较多，恢复的速度会更慢。如果系统的读负载很高，而这段时间从节点无法提供服务，会对系统造成很大的压力。
2. 从库扩容：如果访问量突然增大，此时希望增加从节点分担读负载，如果数据量过大，从节点同步太慢，难以及时应对访问量的暴增。
3. 缓冲区溢出：1和2都是从节点可以正常同步的情形（虽然慢），但是如果数据量过大，导致全量复制阶段主节点的复制缓冲区溢出，从而导致复制中断，则主从节点的数据同步会全量复制->复制缓冲区溢出导致复制中断->重连->全量复制->复制缓冲区溢出导致复制中断……的循环。
4. 超时：如果数据量过大，全量复制阶段主节点fork+保存RDB文件耗时过大，从节点长时间接收不到数据触发超时，主从节点的数据同步同样可能陷入全量复制->超时导致复制中断->重连->全量复制->超时导致复制中断……的循环。

此外，主节点单机内存除了绝对量不能太大，其占用主机内存的比例也不应过大：最好只使用50%-65%的内存，留下30%-45%的内存用于执行bgsave命令和创建复制缓冲区等。





